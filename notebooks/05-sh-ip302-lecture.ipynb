{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a0df71",
   "metadata": {},
   "source": [
    "### Examining the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4043752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with reading the data \n",
    "\n",
    "users_data = pd.read_pickle(\"../../data/users_data_final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e4ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at a preview of the data\n",
    "\n",
    "users_data.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5433956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the shape of the data (rows, columns)\n",
    "\n",
    "users_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c57a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many users do we have in the dataframe?\n",
    "\n",
    "len(np.unique(users_data.user_id))\n",
    "\n",
    "# as expected, this is same as the number of rows in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee5951",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b727415e",
   "metadata": {},
   "source": [
    "### Feature Selection: Drop the Date Joined Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7444de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did you come up with a way to engineer date joined variable?\n",
    "# if not drop this variable\n",
    "\n",
    "users_data.drop(['date_joined'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08ea532",
   "metadata": {},
   "source": [
    "### Feature Engineering: Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167c0682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify all the numerical features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b3c5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing numerical values with 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b421dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify highly correlated variables\n",
    "# look at the correlations, can you see any combinations with\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b8e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify outliers, lets start with age \n",
    "# draw a box plot for age\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a37973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a histogram for age\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d37ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is very minimal skew, let's assume that age is normally distributed and remove the outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f19d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the dataframe, so we only consider ages which are greater than LB and less than UB\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7d9bb9",
   "metadata": {},
   "source": [
    "### Feature Engineering: Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a19849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify all the categorical features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f2af40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to look at the distribution of e.g. jobs across all users\n",
    "# We could use the value_counts function to get a count of unique values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669bcf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify and replace missing values\n",
    "\n",
    "users_data_cleaned.isnull().sum()\n",
    "\n",
    "# question: which feature has the most missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2760bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the feature that has a high percentage of missing data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b47c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with \"Unknown\"\n",
    "\n",
    "users_data_cleaned['job'].fillna(\"Unknown\", inplace = True)\n",
    "users_data_cleaned['education'].fillna(\"Unknown\", inplace = True)\n",
    "users_data_cleaned['contact'].fillna(\"Unknown\", inplace = True)\n",
    "users_data_cleaned['device'].fillna(\"Unknown\", inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae993c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before building our model, we need to encode the categorical data\n",
    "# lots of ways to do that, but we will use pd.get_dummies function\n",
    "# lets start with marital\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d5146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop any feature that has more than 10 categories\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e7aca5",
   "metadata": {},
   "source": [
    "### Building the first machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1c48d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the cleaned data\n",
    "\n",
    "users_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf7bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all numerical\n",
    "\n",
    "users_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048a2ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target, our y\n",
    "# lets say we want to predict the total_amount_usd\n",
    "\n",
    "users_data.total_amount_usd.hist()\n",
    "plt.title(\"Distribution of the total_amount_usd\");\n",
    "\n",
    "# Distribution of variable is skewed, we could also transform the variable in next iteraions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf9ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Outliers exist, in next iterations we may want to remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f23f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Define the target and features\n",
    "# A supervised machine learning algorithm requires both - uses historical data to uncover relationships between other features of your dataset and the target.\n",
    "\n",
    "target_data = users_data.total_amount_usd\n",
    "features = users_data.drop([\"total_amount_usd\"], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c7c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Split the data into a training and test set\n",
    "# The training data is the data we use to train the machine learning algorithm\n",
    "# the test set is used to evaluate the prediction\n",
    "\n",
    "# using this handy function from scikit-learm to split the data into a training and test dataset\n",
    "# we can adjust the test size to our needs, but it's best practise to train the model on 70 - 80% of the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                features, \n",
    "                                                target_data,\n",
    "                                                test_size = 0.2, \n",
    "                                                random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea8fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape of the training data\n",
    "\n",
    "print(\"Training Data\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e0dcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape of the test data \n",
    "\n",
    "print(\"\\nTest Data\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Import the Logistic Regression model from sklearn\n",
    "\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c05593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4. Fit the model on the scaled training data\n",
    "\n",
    "lr.fit(X_train, y_train) \n",
    "\n",
    "# This is your machine learning model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ef612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5. Evaluate how well the model predicts on unseen data\n",
    "\n",
    "y_pred = lr.predict(X_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dd6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"first five predicted total amounts:\", y_pred[0:5])\n",
    "print(\"first five actual total amounts:\", list(y_test[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use r2 to evaluating the model performance.\n",
    "\n",
    "r2_score(y_test, y_pred)\n",
    "\n",
    "# R^2 (coefficient of determination) regression score function.\n",
    "# Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). \n",
    "\n",
    "# Pretty close to 0. Lets see over the next few weeks we can improve the score.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
